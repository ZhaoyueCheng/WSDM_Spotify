{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import layers\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_dir = \"/media/data2/Data/wsdm2019/data/training_set/\"\n",
    "test_set_dir = \"/media/data2/Data/wsdm2019/data/test_set/\"\n",
    "track_features_dir = \"/media/data2/Data/wsdm2019/python/data/track_features/\"\n",
    "\n",
    "train_example_dir = \"/media/data2/Data/wsdm2019/python/data/train_examples/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the maps and vectors\n",
    "import pickle\n",
    "with open(track_features_dir + \"music_vector.pkl\", \"rb\") as f:\n",
    "    vector = pickle.load(f)\n",
    "with open(track_features_dir + \"track2idx.pkl\", \"rb\") as f:\n",
    "    track2idx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip2idx = {'PAD':0, 'UNK':1, False:2, True:3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_embedding = torch.Tensor(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_example_dir+\"sample_examples\", \"rb\") as f:\n",
    "    sample_examples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute force pad everything to length 20 since all lengths are of range 10 to 20\n",
    "max_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences):\n",
    "    sequence_lengths = [len(sequence) for sequence in sequences]\n",
    "#     max_length = max(sequence_lengths)\n",
    "    padded_sequences = [sequences[i] + [0] * (max_length - sequence_lengths[i]) for i in range(len(sequences))]\n",
    "    sequence_masks = [[0.0] * sequence_lengths[i] + [1.0] * (max_length - sequence_lengths[i]) for i in range(len(sequences))]\n",
    "    return torch.cuda.LongTensor(padded_sequences), torch.cuda.ByteTensor(sequence_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take in examples and generate batches\n",
    "import math\n",
    "import copy\n",
    "def batchGen(examples):\n",
    "    inputs_track = []\n",
    "    inputs_skip = []\n",
    "    targets = []\n",
    "    loss_masks = []\n",
    "    sequence_masks = []\n",
    "    \n",
    "    tracks = [example['tracks'] for example in examples]\n",
    "    skip2s = [example['skip2'] for example in examples]\n",
    "    sequence_lengths = [len(track) for track in tracks]\n",
    "    \n",
    "    for track, skip2, sequence_length in zip(tracks, skip2s, sequence_lengths):\n",
    "        \n",
    "        pad_length = max_length - sequence_length\n",
    "        cut = math.floor(sequence_length/2)\n",
    "        \n",
    "        # create song inputs\n",
    "        input_track = copy.deepcopy(track) + [0] * pad_length\n",
    "        inputs_track.append(input_track)        \n",
    "        \n",
    "        # create skip inputs and mask out the correct answer\n",
    "        input_skip = copy.deepcopy(skip2) + [0] * pad_length\n",
    "        input_skip[cut:sequence_length] = (sequence_length-cut) * [1]\n",
    "        inputs_skip.append(input_skip)\n",
    "\n",
    "        # create targets\n",
    "        target = copy.deepcopy(skip2)\n",
    "        target = [item-2 for item in target] + [0] * pad_length\n",
    "        targets.append(target)\n",
    "\n",
    "        # create loss masks\n",
    "        mask = [0.0] * cut + [1.0] * (sequence_length-cut) + [0.0] * pad_length\n",
    "        loss_masks.append(mask)\n",
    "        \n",
    "        # create sequence masks\n",
    "        sequence_mask = [0.0] * sequence_length + [1.0] * pad_length\n",
    "        sequence_masks.append(sequence_mask)\n",
    "    \n",
    "    return torch.cuda.LongTensor(inputs_track), torch.cuda.LongTensor(inputs_skip), torch.cuda.FloatTensor(targets), torch.cuda.FloatTensor(loss_masks), torch.cuda.ByteTensor(sequence_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d,e = batchGen(sample_examples[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_encoder import RNNEncoder\n",
    "encoder = RNNEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNEncoder(\n",
       "  (song_embedding): Embedding(3706389, 8, padding_idx=0)\n",
       "  (skip_embedding): Embedding(4, 2, padding_idx=0)\n",
       "  (bidirectional_rnn): StackedBRNN(\n",
       "    (rnns): ModuleList(\n",
       "      (0): LSTM(10, 10, bidirectional=True)\n",
       "      (1): LSTM(20, 10, bidirectional=True)\n",
       "    )\n",
       "  )\n",
       "  (linear1): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.init_embeddings(music_embedding)\n",
    "encoder.cuda()\n",
    "encoder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joey/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "encoder_result = encoder.forward(a,b,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn = torch.nn.BCELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = (loss_fcn(encoder_result, c) * d).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = encoder_result * d > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = np.array(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35869566"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((res == gt) * np.array(d)) / np.sum(np.array(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joey/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 200 accuracy: 0.6280155904591084 loss: 0.27692155353724957\n",
      "step: 400 accuracy: 0.6544649860262871 loss: 0.268240697234869\n",
      "step: 600 accuracy: 0.6529144057631493 loss: 0.26946472719311715\n",
      "step: 800 accuracy: 0.6530436463654041 loss: 0.26894513636827466\n",
      "step: 1000 accuracy: 0.6595906069874764 loss: 0.2656978008151054\n",
      "step: 1200 accuracy: 0.6570003083348275 loss: 0.2661834440380335\n",
      "step: 1400 accuracy: 0.6607881060242653 loss: 0.2670547955483198\n",
      "step: 1600 accuracy: 0.6592116144299507 loss: 0.2659791777282953\n",
      "step: 1800 accuracy: 0.6574752444028854 loss: 0.2667047675698996\n",
      "step: 2000 accuracy: 0.663350087404251 loss: 0.2643253093957901\n",
      "step: 2200 accuracy: 0.6630785179138183 loss: 0.26477712623775007\n",
      "step: 2400 accuracy: 0.6588929070532322 loss: 0.26595423512160776\n",
      "step: 2600 accuracy: 0.6658255207538605 loss: 0.2644596965610981\n",
      "step: 2800 accuracy: 0.6661141327023506 loss: 0.2631688713282347\n",
      "step: 3000 accuracy: 0.657518829703331 loss: 0.26649584248661995\n",
      "step: 3200 accuracy: 0.6662200123071671 loss: 0.26389062993228435\n",
      "step: 3400 accuracy: 0.6531912922859192 loss: 0.2667203712463379\n",
      "step: 3600 accuracy: 0.6598540213704109 loss: 0.26557965531945227\n",
      "step: 3800 accuracy: 0.6635202142596245 loss: 0.2639752008765936\n",
      "step: 4000 accuracy: 0.6682126340270043 loss: 0.2621427971869707\n",
      "step: 4200 accuracy: 0.6613897508382798 loss: 0.2639320109039545\n",
      "step: 4400 accuracy: 0.6623530089855194 loss: 0.26476177386939526\n",
      "step: 4600 accuracy: 0.6657311627268792 loss: 0.2654308457672596\n",
      "step: 4800 accuracy: 0.6598188650608062 loss: 0.26534462176263335\n",
      "step: 5000 accuracy: 0.6642615160346031 loss: 0.2627175595611334\n",
      "step: 5200 accuracy: 0.6615633168816566 loss: 0.2656655493378639\n",
      "step: 5400 accuracy: 0.6634771129488946 loss: 0.2638947606086731\n",
      "step: 5600 accuracy: 0.6627373644709587 loss: 0.26198257707059386\n",
      "step: 5800 accuracy: 0.6639967906475067 loss: 0.26360151946544647\n",
      "step: 6000 accuracy: 0.6664008939266205 loss: 0.2619789749383926\n",
      "step: 6200 accuracy: 0.6612542080879211 loss: 0.26459748968482016\n",
      "step: 6400 accuracy: 0.6679968604445458 loss: 0.2622343529760838\n",
      "step: 6600 accuracy: 0.667707231938839 loss: 0.2612474732846022\n",
      "step: 6800 accuracy: 0.6681038650870323 loss: 0.2616091973334551\n",
      "step: 7000 accuracy: 0.6648303887248039 loss: 0.2628403400629759\n",
      "step: 7200 accuracy: 0.6713802015781403 loss: 0.26093735836446286\n",
      "step: 7400 accuracy: 0.6690137764811516 loss: 0.26087312527000905\n",
      "step: 7600 accuracy: 0.6718939363956451 loss: 0.2598996141552925\n",
      "step: 7800 accuracy: 0.6706677147746086 loss: 0.2605989445745945\n",
      "step: 8000 accuracy: 0.6686295434832573 loss: 0.2597180438041687\n",
      "step: 8200 accuracy: 0.6704924091696739 loss: 0.26020637325942514\n",
      "step: 8400 accuracy: 0.675230795443058 loss: 0.2581791340559721\n",
      "step: 8600 accuracy: 0.6724926140904427 loss: 0.2598908308893442\n",
      "step: 8800 accuracy: 0.6751067119836808 loss: 0.25957165986299513\n",
      "step: 9000 accuracy: 0.6689007905125618 loss: 0.2609583530575037\n",
      "step: 9200 accuracy: 0.6706077527999877 loss: 0.2597541915625334\n",
      "step: 9400 accuracy: 0.6746870929002762 loss: 0.2574369502067566\n",
      "step: 9600 accuracy: 0.6773789620399475 loss: 0.25809949621558187\n",
      "step: 9800 accuracy: 0.6720544132590294 loss: 0.2584988813847303\n",
      "step: 10000 accuracy: 0.6733908459544182 loss: 0.25903217248618604\n",
      "step: 10200 accuracy: 0.6734543117880821 loss: 0.2606195405870676\n",
      "step: 10400 accuracy: 0.6691582062840462 loss: 0.2604050462692976\n",
      "step: 10600 accuracy: 0.6724644333124161 loss: 0.258513867855072\n",
      "step: 10800 accuracy: 0.674328396320343 loss: 0.26026684187352656\n",
      "step: 11000 accuracy: 0.6709890550374985 loss: 0.2593772257864475\n",
      "step: 11200 accuracy: 0.6755100786685944 loss: 0.256330623999238\n",
      "step: 11400 accuracy: 0.6798069143295288 loss: 0.2563196862488985\n",
      "step: 11600 accuracy: 0.6877140069007873 loss: 0.2527693296223879\n",
      "step: 11800 accuracy: 0.6806450986862183 loss: 0.2554923678189516\n",
      "step: 12000 accuracy: 0.6877501088380814 loss: 0.25226104743778704\n",
      "step: 12200 accuracy: 0.6842344212532043 loss: 0.2533627024292946\n",
      "step: 12400 accuracy: 0.6832234206795692 loss: 0.25300012111663817\n",
      "step: 12600 accuracy: 0.6852249735593796 loss: 0.2528078228235245\n",
      "step: 12800 accuracy: 0.6895838093757629 loss: 0.25156417101621625\n",
      "step: 13000 accuracy: 0.6897295138239861 loss: 0.25133453018963337\n",
      "step: 13200 accuracy: 0.6929720416665077 loss: 0.24921155527234076\n",
      "step: 13400 accuracy: 0.6861691126227378 loss: 0.25240859247744085\n",
      "step: 13600 accuracy: 0.6900843325257301 loss: 0.24950300611555576\n",
      "step: 13800 accuracy: 0.6919348829984665 loss: 0.24991568490862848\n",
      "step: 14000 accuracy: 0.6913917049765587 loss: 0.24933250494301318\n",
      "step: 14200 accuracy: 0.69372852653265 loss: 0.2492210228741169\n",
      "step: 14400 accuracy: 0.6918282356858253 loss: 0.25006948709487914\n",
      "step: 14600 accuracy: 0.6893541422486306 loss: 0.24971571072936058\n",
      "step: 14800 accuracy: 0.6903827625513077 loss: 0.25031957298517227\n",
      "step: 15000 accuracy: 0.6972201856970787 loss: 0.2450183007866144\n",
      "step: 15200 accuracy: 0.6939314183592796 loss: 0.24947178348898888\n",
      "step: 15400 accuracy: 0.6924370700120925 loss: 0.2485159257799387\n",
      "step: 15600 accuracy: 0.6927445021271705 loss: 0.24860067307949066\n",
      "step: 15800 accuracy: 0.6932956743240356 loss: 0.2498747843503952\n",
      "step: 16000 accuracy: 0.6901293355226517 loss: 0.24952718742191793\n",
      "step: 16200 accuracy: 0.6917844620347023 loss: 0.24914295472204684\n",
      "step: 16400 accuracy: 0.6886827883124351 loss: 0.25094252720475196\n",
      "step: 16600 accuracy: 0.687635507285595 loss: 0.24980959720909596\n",
      "step: 16800 accuracy: 0.6956257075071335 loss: 0.2464180424809456\n",
      "step: 17000 accuracy: 0.70133096575737 loss: 0.24451303012669087\n",
      "step: 17200 accuracy: 0.7054304015636444 loss: 0.2410845224559307\n",
      "step: 17400 accuracy: 0.7031799930334092 loss: 0.24350279182195664\n",
      "step: 17600 accuracy: 0.7034331217408181 loss: 0.24154308564960958\n",
      "step: 17800 accuracy: 0.702905063033104 loss: 0.2426625344157219\n",
      "step: 18000 accuracy: 0.7022816061973571 loss: 0.24206077851355076\n",
      "step: 18200 accuracy: 0.7075161409378051 loss: 0.23947957031428813\n",
      "step: 18400 accuracy: 0.70944629997015 loss: 0.24008374877274036\n",
      "step: 18600 accuracy: 0.709642328619957 loss: 0.23984145559370518\n",
      "step: 18800 accuracy: 0.7161914867162704 loss: 0.23615846879780292\n",
      "step: 19000 accuracy: 0.7066530790925026 loss: 0.24103463225066663\n",
      "step: 19200 accuracy: 0.709954414665699 loss: 0.23848866865038873\n",
      "step: 19400 accuracy: 0.7074847495555878 loss: 0.23999921187758447\n",
      "step: 19600 accuracy: 0.7086024931073189 loss: 0.23916441977024078\n",
      "step: 19800 accuracy: 0.7146348857879639 loss: 0.23678282409906387\n",
      "step: 20000 accuracy: 0.7081650376319886 loss: 0.2392461381852627\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c6c43520c762>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mencoder_result\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlm\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "encoder_optimizer = optim.Adamax(params=encoder.parameters(), lr = 0.01, weight_decay = 0.0)\n",
    "step = 0\n",
    "\n",
    "avg_acc = 0\n",
    "avg_loss = 0\n",
    "\n",
    "for epoch in range(10):\n",
    "    dataset_size = len(sample_examples)\n",
    "    batch_size = 32\n",
    "    print(\"epoch: \" + str(epoch))\n",
    "    for start_index in range(0, dataset_size, batch_size):\n",
    "        end_index = min(start_index + batch_size, dataset_size)\n",
    "        batch = sample_examples[start_index: end_index]\n",
    "        \n",
    "        it, isk, t, lm, sm = batchGen(batch)\n",
    "        \n",
    "        encoder_result = encoder.forward(it, isk, sm)\n",
    "        loss = (loss_fcn(encoder_result, t) * lm).mean()\n",
    "        encoder_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), 5)\n",
    "        \n",
    "        encoder_optimizer.step()\n",
    "        step += 1\n",
    "        \n",
    "        res = (encoder_result * lm > 0.5).detach().cpu().numpy()\n",
    "        gt = t.detach().cpu().numpy()\n",
    "        acc = np.sum((res == gt) * np.array(lm)) / np.sum(np.array(lm))\n",
    "        \n",
    "        avg_acc += acc\n",
    "        avg_loss += loss.detach().cpu().numpy()\n",
    "        \n",
    "        if step % 200 == 0:\n",
    "            print(\"step: \" + str(step) + \" accuracy: \" + str(avg_acc/200) + \" loss: \" + str(avg_loss/200))\n",
    "            avg_acc = 0\n",
    "            avg_loss = 0\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
