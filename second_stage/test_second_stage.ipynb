{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import tqdm\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load track features into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_features_dir = \"/media/data2/Data/wsdm2019/data/track_features/\"\n",
    "track_feature_files = sorted(glob.glob(track_features_dir+\"*.csv\"))\n",
    "track_feature_dir_0 = track_feature_files[0]\n",
    "track_feature_0 = pd.read_csv(track_feature_dir_0)\n",
    "\n",
    "track_feature_dir_1 = track_feature_files[1]\n",
    "track_feature_1 = pd.read_csv(track_feature_dir_1)\n",
    "\n",
    "track_feature_all = track_feature_0.append(track_feature_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get this so that it's easier to merge with train indexes\n",
    "track_feature_id_index = track_feature_all.set_index('track_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load session features into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_dir = \"/media/data2/Data/wsdm2019/data/training_set/\"\n",
    "second_stage_file_dir = \"/media/data2/Data/wsdm2019/python/data/second_stage/\"\n",
    "\n",
    "train_files = sorted(glob.glob(train_set_dir+\"*.csv\"))\n",
    "\n",
    "catboost_files = train_files[500:]\n",
    "\n",
    "temp_catboost_train_file_size = 4\n",
    "temp_catboost_valid_file_size = 1\n",
    "\n",
    "catboost_train_files = catboost_files[:temp_catboost_train_file_size][0:1]\n",
    "catboost_valid_files = catboost_files[temp_catboost_train_file_size:temp_catboost_valid_file_size + temp_catboost_train_file_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_list = []\n",
    "valid_df_list = []\n",
    "\n",
    "for f in catboost_train_files:\n",
    "    s_f = second_stage_file_dir + f[45:-4] + \"_second_stage.csv\"\n",
    "    df_raw = pd.read_csv(f).rename(index=str, columns={\"track_id_clean\": \"track_id\"})\n",
    "    df_f = pd.read_csv(s_f)\n",
    "    df_raw['logits'] = df_f.iloc[:,0].values\n",
    "    train_df_list.append(df_raw)    \n",
    "\n",
    "for f in catboost_valid_files:\n",
    "    s_f = second_stage_file_dir + f[45:-4] + \"_second_stage.csv\"\n",
    "    df_raw = pd.read_csv(f).rename(index=str, columns={\"track_id_clean\": \"track_id\"})\n",
    "    df_f = pd.read_csv(s_f)\n",
    "    df_raw['logits'] = df_f.iloc[:,0].values\n",
    "    valid_df_list.append(df_raw)\n",
    "    \n",
    "catboost_train_raw = pd.concat(train_df_list, ignore_index=True)\n",
    "catboost_valid_raw = pd.concat(valid_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_train_raw_group = catboost_train_raw.groupby('session_id')\n",
    "ngroups = catboost_train_raw_group.ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940033\n"
     ]
    }
   ],
   "source": [
    "print(ngroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_dropped_columns = ['session_id', 'track_id', 'session_position']\n",
    "session_bool_columns = ['skip_1', 'skip_2', 'skip_3', 'not_skipped', 'context_switch', 'no_pause_before_play', 'short_pause_before_play',\n",
    "                'long_pause_before_play', 'hist_user_behavior_is_shuffle', 'premium']\n",
    "session_numerical_columns = ['hist_user_behavior_n_seekfwd', 'hist_user_behavior_n_seekback']\n",
    "session_numerical_columns_range_map = {'hist_user_behavior_n_seekfwd': (0,100), 'hist_user_behavior_n_seekback': (0,100)}\n",
    "session_categorical_columns = ['context_type', 'hist_user_behavior_reason_start', 'hist_user_behavior_reason_end', 'session_length', 'hour_of_day', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_dropped_columns = ['track_id']\n",
    "track_numerical_columns = ['duration', 'us_popularity_estimate', 'acousticness', 'beat_strength', 'bounciness', 'danceability',\n",
    "                             'dyn_range_mean', 'energy', 'flatness', 'instrumentalness', 'liveness', 'loudness', 'mechanism', \n",
    "                             'organism', 'speechiness', 'tempo', 'valence']\n",
    "track_vector_columns = ['acoustic_vector_0', 'acoustic_vector_1', 'acoustic_vector_2', \n",
    "                        'acoustic_vector_3', 'acoustic_vector_4', 'acoustic_vector_5',\n",
    "                        'acoustic_vector_6', 'acoustic_vector_7']\n",
    "track_categorical_columns = ['release_year', 'key', 'mode', 'time_signature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_session_history_summarization(test_group_history):\n",
    "#     num_feature_list = []\n",
    "#     cat_feature_list = []\n",
    "#     for feature in test_group_history.columns:\n",
    "#         if feature in history_bool_columns:\n",
    "#             col = test_group_history[feature].astype(int)\n",
    "#             num_feature_list.extend([col.mean(), col.var(), col.mode()[0]])\n",
    "#         elif feature in history_numerical_columns:\n",
    "#             (mi, ma) = history_numerical_columns_range_map[feature]\n",
    "#             col = test_group_history[feature].clip(mi, ma)\n",
    "#             col = (col - mi) / (ma - mi)\n",
    "#             num_feature_list.extend([col.mean(), col.var()])\n",
    "#         elif feature in history_categorical_columns:\n",
    "#             col = test_group_history[feature]\n",
    "#             cat_feature_list.append(col.mode()[0])\n",
    "#     return num_feature_list, cat_feature_list\n",
    "def get_session_history_summarization(test_group_history):\n",
    "    num_feature_list = []\n",
    "    cat_feature_list = []\n",
    "    \n",
    "    for feature in test_group_history.columns:\n",
    "        if feature in numerical_columns:\n",
    "            (mi, ma) = history_numerical_columns_range_map[feature]\n",
    "            col = test_group_history[feature].clip(mi, ma)\n",
    "            col = (col - mi) / (ma - mi)\n",
    "            num_feature_list.extend([col.mean(), col.var()])\n",
    "    \n",
    "    bool_cols = test_group_history[history_bool_columns].astype(int)\n",
    "    num_feature_list.extend(bool_cols.mean().tolist())\n",
    "    num_feature_list.extend(bool_cols.var().tolist())\n",
    "    num_feature_list.extend(bool_cols.mode().iloc[0].tolist())\n",
    "    \n",
    "    cat_cols = test_group_history[history_categorical_columns]\n",
    "    \n",
    "    cat_feature_list.extend(cat_cols.mode().iloc[0].astype(str).tolist())\n",
    "    \n",
    "    return num_feature_list, cat_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_df(track_list):\n",
    "    return track_feature_id_index.loc[track_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_track_feature(self_track_df):\n",
    "    num_feature_list = []\n",
    "    cat_feature_list = []\n",
    "#     for feature in self_track_df.columns:\n",
    "#         print(feature)\n",
    "#     if feature in predict_numerical_columns:\n",
    "    num_feature_list.extend(self_track_df[predict_numerical_columns].tolist())\n",
    "    cat_feature_list.extend(self_track_df[predict_categorical_columns].astype(str).tolist())\n",
    "    return num_feature_list, cat_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tracks_df_summarization_feature(tracks_df):\n",
    "    num_feature_list = []\n",
    "    cat_feature_list = []\n",
    "    \n",
    "    num_feature_list.extend(tracks_df[track_numerical_columns].mean().tolist())\n",
    "#     num_feature_list.extend(tracks_df[track_numerical_columns].var().tolist())\n",
    "    num_feature_list.extend(tracks_df[track_numerical_columns].min().tolist())\n",
    "    num_feature_list.extend(tracks_df[track_numerical_columns].max().tolist())\n",
    "    \n",
    "    cat_feature_list.extend(tracks_df[track_categorical_columns].mode().iloc[0].astype(str).tolist())\n",
    "    \n",
    "    return num_feature_list, cat_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat_train = []\n",
    "cat_feat_train = []\n",
    "target_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "num_feat_train = []\n",
    "cat_feat_train = []\n",
    "target_train = []\n",
    "\n",
    "for name, test_group in catboost_train_raw_group:\n",
    "    \n",
    "    test_group_history = test_group.iloc[:math.floor(test_group['session_position'].size / 2)].rename(index=str, columns={\"track_id_clean\": \"track_id\"})\n",
    "    test_group_predict_all = test_group.iloc[math.floor(test_group['session_position'].size / 2):].rename(index=str, columns={\"track_id_clean\": \"track_id\"})\n",
    "    test_group_predict = test_group_predict_all.iloc[:,:4]\n",
    "    test_group_predict['logits'] = test_group_predict_all['logits']\n",
    "    test_group_target = test_group_predict_all.iloc[:, 5].astype(int)\n",
    "\n",
    "    target_train.extend(test_group_target.tolist())\n",
    "\n",
    "    # first get the summarization data\n",
    "    num_feat_hist, cat_feat_hist = get_session_history_summarization(test_group_history)\n",
    "\n",
    "    # use the append of two piecese because of the structure of test set\n",
    "    all_track_ids = test_group_history['track_id'].append(test_group_predict['track_id'])\n",
    "\n",
    "    # used to fill in 0s if it's the last song in the current history since it don't have after tracks\n",
    "    num_feat_after_sum_len = 51\n",
    "    cat_feat_after_sum_len = 4\n",
    "\n",
    "    isLast = False\n",
    "    for index, row in test_group_predict.iterrows():\n",
    "        num_feat_predict_row = []\n",
    "        cat_feat_predict_row = []\n",
    "\n",
    "        num_feat_predict_row.extend(num_feat_hist)\n",
    "        cat_feat_predict_row.extend(cat_feat_hist)\n",
    "\n",
    "        # add categorical variable session_position (session length is already included in cat_feat_hist)\n",
    "        session_position = row[1]\n",
    "        cat_feat_predict_row.append(session_position)\n",
    "\n",
    "        # use the append of two piecese because of the structure of test set\n",
    "        entire_track_id = test_group_history['track_id'].append(test_group_predict['track_id'])\n",
    "\n",
    "        before_tracks = all_track_ids[:(session_position - 1)]\n",
    "        current_track = all_track_ids[(session_position - 1)]\n",
    "        after_tracks = all_track_ids[(session_position):]\n",
    "        if (len(after_tracks) == 0):\n",
    "            isLast = True\n",
    "\n",
    "        # count of how many times this item have appeared before and after current track\n",
    "        before_count = (before_tracks == current_track).sum() / len(before_tracks)\n",
    "        before_proportion = before_count / len(before_tracks)\n",
    "        if isLast:\n",
    "            after_count = 0\n",
    "            after_proportion = 0\n",
    "        else:\n",
    "            after_count = (after_tracks == current_track).sum() / len(after_tracks)\n",
    "            after_proportion = after_count / len(after_tracks)\n",
    "        num_feat_predict_row.extend([after_count, after_proportion, before_count, before_proportion])\n",
    "\n",
    "        # get the three corresponding dataframes\n",
    "        current_track_df = get_track_df(current_track)\n",
    "        before_tracks_df = get_track_df(before_tracks)\n",
    "        after_tracks_df = get_track_df(after_tracks)\n",
    "\n",
    "        # get current track data\n",
    "        num_feat_current, cat_feat_current = get_current_track_feature(current_track_df)\n",
    "        num_feat_predict_row.extend(num_feat_current)\n",
    "        cat_feat_predict_row.extend(cat_feat_current)\n",
    "\n",
    "        # get before tracks summarization data\n",
    "        num_feat_before_sum, cat_feat_before_sum = get_tracks_df_summarization_feature(before_tracks_df)\n",
    "        num_feat_predict_row.extend(num_feat_before_sum)\n",
    "        cat_feat_predict_row.extend(cat_feat_before_sum)\n",
    "\n",
    "        # get after tracks summarizaiton data\n",
    "        if isLast:\n",
    "            num_feat_after_sum = [0] * num_feat_after_sum_len\n",
    "            cat_feat_after_sum = ['last'] * cat_feat_after_sum_len\n",
    "        else:\n",
    "            num_feat_after_sum, cat_feat_after_sum = get_tracks_df_summarization_feature(after_tracks_df)\n",
    "\n",
    "        num_feat_predict_row.extend(num_feat_after_sum)\n",
    "        cat_feat_predict_row.extend(cat_feat_after_sum)\n",
    "\n",
    "        # add numerical feature logits\n",
    "        logit = row[4]\n",
    "        num_feat_predict_row.append(logit)\n",
    "\n",
    "        num_feat_train.append(num_feat_predict_row)\n",
    "        cat_feat_train.append(cat_feat_predict_row)\n",
    "        \n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:\n",
    "        print(counter)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8334"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_feat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8334"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_feat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8334"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat_valid = num_feat_train[-5000:]\n",
    "cat_feat_valid = cat_feat_train[-5000:]\n",
    "target_valid = target_train[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = num_feat_train[:-5000]\n",
    "c_train = cat_feat_train[:-5000]\n",
    "t = target_train[:-5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [a+b for a,b in zip(c_train, n_train)]\n",
    "valid = [a+b for a,b in zip(cat_feat_valid, num_feat_valid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "p = Pool(train, t, list(range(19)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model = CatBoostClassifier(iterations=100,\n",
    "                              eval_metric='AUC',\n",
    "                              learning_rate=0.02,\n",
    "                              max_depth=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model.fit(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_valid = [i[-1] for i in num_feat_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((np.array(logits_valid) > 0.5) == target_valid).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "686"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(cb_model.predict(valid) == target_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_group(name, test_group):\n",
    "    num_feat_train = []\n",
    "    cat_feat_train = []\n",
    "    target_train = []\n",
    "    \n",
    "    test_group_history = test_group.iloc[:math.floor(test_group['session_position'].size / 2)].rename(index=str, columns={\"track_id_clean\": \"track_id\"})\n",
    "    test_group_predict_all = test_group.iloc[math.floor(test_group['session_position'].size / 2):].rename(index=str, columns={\"track_id_clean\": \"track_id\"})\n",
    "    test_group_predict = test_group_predict_all.iloc[:,:4]\n",
    "    test_group_predict['logits'] = test_group_predict_all['logits']\n",
    "    test_group_target = test_group_predict_all.iloc[:, 5].astype(int)\n",
    "\n",
    "    target_train.extend(test_group_target.tolist())\n",
    "\n",
    "    # first get the summarization data\n",
    "    num_feat_hist, cat_feat_hist = get_session_history_summarization(test_group_history)\n",
    "\n",
    "    # use the append of two piecese because of the structure of test set\n",
    "    all_track_ids = test_group_history['track_id'].append(test_group_predict['track_id'])\n",
    "\n",
    "    # used to fill in 0s if it's the last song in the current history since it don't have after tracks\n",
    "    num_feat_after_sum_len = 51\n",
    "    cat_feat_after_sum_len = 4\n",
    "\n",
    "    isLast = False\n",
    "    for index, row in test_group_predict.iterrows():\n",
    "        num_feat_predict_row = []\n",
    "        cat_feat_predict_row = []\n",
    "\n",
    "        num_feat_predict_row.extend(num_feat_hist)\n",
    "        cat_feat_predict_row.extend(cat_feat_hist)\n",
    "\n",
    "        # add categorical variable session_position (session length is already included in cat_feat_hist)\n",
    "        session_position = row[1]\n",
    "        cat_feat_predict_row.append(session_position)\n",
    "\n",
    "        # use the append of two piecese because of the structure of test set\n",
    "        entire_track_id = test_group_history['track_id'].append(test_group_predict['track_id'])\n",
    "\n",
    "        before_tracks = all_track_ids[:(session_position - 1)]\n",
    "        current_track = all_track_ids[(session_position - 1)]\n",
    "        after_tracks = all_track_ids[(session_position):]\n",
    "        if (len(after_tracks) == 0):\n",
    "            isLast = True\n",
    "\n",
    "        # count of how many times this item have appeared before and after current track\n",
    "        before_count = (before_tracks == current_track).sum() / len(before_tracks)\n",
    "        before_proportion = before_count / len(before_tracks)\n",
    "        if isLast:\n",
    "            after_count = 0\n",
    "            after_proportion = 0\n",
    "        else:\n",
    "            after_count = (after_tracks == current_track).sum() / len(after_tracks)\n",
    "            after_proportion = after_count / len(after_tracks)\n",
    "        num_feat_predict_row.extend([after_count, after_proportion, before_count, before_proportion])\n",
    "\n",
    "        # get the three corresponding dataframes\n",
    "        current_track_df = get_track_df(current_track)\n",
    "        before_tracks_df = get_track_df(before_tracks)\n",
    "        after_tracks_df = get_track_df(after_tracks)\n",
    "\n",
    "        # get current track data\n",
    "        num_feat_current, cat_feat_current = get_current_track_feature(current_track_df)\n",
    "        num_feat_predict_row.extend(num_feat_current)\n",
    "        cat_feat_predict_row.extend(cat_feat_current)\n",
    "\n",
    "        # get before tracks summarization data\n",
    "        num_feat_before_sum, cat_feat_before_sum = get_tracks_df_summarization_feature(before_tracks_df)\n",
    "        num_feat_predict_row.extend(num_feat_before_sum)\n",
    "        cat_feat_predict_row.extend(cat_feat_before_sum)\n",
    "\n",
    "        # get after tracks summarizaiton data\n",
    "        if isLast:\n",
    "            num_feat_after_sum = [0] * num_feat_after_sum_len\n",
    "            cat_feat_after_sum = ['last'] * cat_feat_after_sum_len\n",
    "        else:\n",
    "            num_feat_after_sum, cat_feat_after_sum = get_tracks_df_summarization_feature(after_tracks_df)\n",
    "\n",
    "        num_feat_predict_row.extend(num_feat_after_sum)\n",
    "        cat_feat_predict_row.extend(cat_feat_after_sum)\n",
    "\n",
    "        # add numerical feature logits\n",
    "        logit = row[4]\n",
    "        num_feat_predict_row.append(logit)\n",
    "\n",
    "        num_feat_train.append(num_feat_predict_row)\n",
    "        cat_feat_train.append(cat_feat_predict_row)\n",
    "        \n",
    "    return {\n",
    "        'name': name,\n",
    "        'num_feat_train': num_feat_train,\n",
    "        'cat_feat_train': cat_feat_train,\n",
    "        'target_train': target_train\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-218:\n",
      "Process ForkPoolWorker-236:\n",
      "Process ForkPoolWorker-220:\n",
      "Process ForkPoolWorker-232:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-231:\n",
      "Process ForkPoolWorker-227:\n",
      "Process ForkPoolWorker-238:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-234:\n",
      "Process ForkPoolWorker-212:\n",
      "Process ForkPoolWorker-224:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-213:\n",
      "Process ForkPoolWorker-239:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-228:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-241:\n",
      "Process ForkPoolWorker-223:\n",
      "Process ForkPoolWorker-237:\n",
      "Process ForkPoolWorker-215:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-211:\n",
      "Process ForkPoolWorker-226:\n",
      "Process ForkPoolWorker-233:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-235:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "Process ForkPoolWorker-222:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-214:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-221:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-210:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Process ForkPoolWorker-219:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-225:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Process ForkPoolWorker-216:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Process ForkPoolWorker-240:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Process ForkPoolWorker-229:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-230:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-217:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 180, in _new_Index\n",
      "    return cls.__new__(cls, **d)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 431, in __new__\n",
      "    return cls._simple_new(subarr, name)\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 493, in _simple_new\n",
      "    for k, v in compat.iteritems(kwargs):\n",
      "  File \"/home/joey/anaconda3/envs/pytorch/lib/python3.6/site-packages/pandas/compat/__init__.py\", line 206, in iteritems\n",
      "    return iter(obj.items(**kw))\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "pool = multiprocessing.Pool(processes=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-605-2e5950f210b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatboost_train_raw_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "result = pool.map(process_group, catboost_train_raw_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
